{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Symbol                 Date       Open      Close       High  \\\n",
      "0          RPD  2018-01-02 00:00:00  18.660000  19.010000  19.090000   \n",
      "1          RPD  2018-01-03 00:00:00  19.040001  19.350000  19.650000   \n",
      "2          RPD  2018-01-04 00:00:00  19.389999  19.980000  20.000000   \n",
      "3          RPD  2018-01-05 00:00:00  20.000000  20.010000  20.100000   \n",
      "4          RPD  2018-01-08 00:00:00  20.020000  20.350000  20.500000   \n",
      "...        ...                  ...        ...        ...        ...   \n",
      "5177034    RNG  2023-03-14 00:00:00  32.180000  31.590000  32.680000   \n",
      "5177035    OGI  2023-03-15 00:00:00   0.650000   0.640000   0.651000   \n",
      "5177036    RNG  2023-03-15 00:00:00  31.320000  32.380001  32.549999   \n",
      "5177037    OGI  2023-03-16 00:00:00   0.640000   0.649000   0.667000   \n",
      "5177038    RNG  2023-03-16 00:00:00  32.419998  31.969999  32.580002   \n",
      "\n",
      "               Low     Volume   AdjClose  \n",
      "0        18.500000   124200.0  19.010000  \n",
      "1        19.040001   204100.0  19.350000  \n",
      "2        19.389999   177900.0  19.980000  \n",
      "3        19.719999   204400.0  20.010000  \n",
      "4        19.950001   237100.0  20.350000  \n",
      "...            ...        ...        ...  \n",
      "5177034  31.230000  2080300.0  31.590000  \n",
      "5177035   0.629000   822400.0   0.640000  \n",
      "5177036  30.990000  1694200.0  32.380001  \n",
      "5177037   0.629000  1386100.0   0.649000  \n",
      "5177038  31.180000  1495200.0  31.969999  \n",
      "\n",
      "[5177039 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#TODO: add in extra datasets \n",
    "df = pd.read_csv('history.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Symbol       Date       Open      Close       High        Low  \\\n",
      "0          RPD 2018-01-02  18.660000  19.010000  19.090000  18.500000   \n",
      "1          RPD 2018-01-03  19.040001  19.350000  19.650000  19.040001   \n",
      "2          RPD 2018-01-04  19.389999  19.980000  20.000000  19.389999   \n",
      "3          RPD 2018-01-05  20.000000  20.010000  20.100000  19.719999   \n",
      "4          RPD 2018-01-08  20.020000  20.350000  20.500000  19.950001   \n",
      "...        ...        ...        ...        ...        ...        ...   \n",
      "5177034    RNG 2023-03-14  32.180000  31.590000  32.680000  31.230000   \n",
      "5177035    OGI 2023-03-15   0.650000   0.640000   0.651000   0.629000   \n",
      "5177036    RNG 2023-03-15  31.320000  32.380001  32.549999  30.990000   \n",
      "5177037    OGI 2023-03-16   0.640000   0.649000   0.667000   0.629000   \n",
      "5177038    RNG 2023-03-16  32.419998  31.969999  32.580002  31.180000   \n",
      "\n",
      "            Volume   AdjClose  Year  Month  DayOfWeek  WeekOfYear  \n",
      "0         124200.0  19.010000  2018      1          1           1  \n",
      "1         204100.0  19.350000  2018      1          2           1  \n",
      "2         177900.0  19.980000  2018      1          3           1  \n",
      "3         204400.0  20.010000  2018      1          4           1  \n",
      "4         237100.0  20.350000  2018      1          0           2  \n",
      "...            ...        ...   ...    ...        ...         ...  \n",
      "5177034  2080300.0  31.590000  2023      3          1          11  \n",
      "5177035   822400.0   0.640000  2023      3          2          11  \n",
      "5177036  1694200.0  32.380001  2023      3          2          11  \n",
      "5177037  1386100.0   0.649000  2023      3          3          11  \n",
      "5177038  1495200.0  31.969999  2023      3          3          11  \n",
      "\n",
      "[5177039 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#Add in special date columns\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df.apply(lambda row: row['Date'].year, axis=1)\n",
    "df['Month'] = df.apply(lambda row: row['Date'].month, axis=1)\n",
    "df['DayOfWeek'] = df.apply(lambda row: row['Date'].weekday(), axis=1)\n",
    "df['WeekOfYear'] = df.apply(lambda row: row['Date'].isocalendar()[1], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Symbol', 'Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'AdjClose',\n",
      "       'Year', 'Month', 'DayOfWeek', 'WeekOfYear', 'sin_DayOfWeek',\n",
      "       'cos_DayOfWeek', 'sin_Month', 'cos_Month', 'sin_WeekOfYear',\n",
      "       'cos_WeekOfYear'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_cyclical_features(df, col_name, period, start_num=0):\n",
    "    kwargs = {\n",
    "        f'sin_{col_name}' : lambda x: np.sin(2*np.pi*(df[col_name]-start_num)/period),\n",
    "        f'cos_{col_name}' : lambda x: np.cos(2*np.pi*(df[col_name]-start_num)/period)    \n",
    "             }\n",
    "    return df.assign(**kwargs)\n",
    "\n",
    "df = generate_cyclical_features(df, 'DayOfWeek', 7, 0)\n",
    "df = generate_cyclical_features(df, 'Month', 12, 1)\n",
    "df = generate_cyclical_features(df, 'WeekOfYear', 52, 0)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Symbol', 'Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'AdjClose',\n",
      "       'Year', 'Month', 'DayOfWeek', 'WeekOfYear', 'sin_DayOfWeek',\n",
      "       'cos_DayOfWeek', 'sin_Month', 'cos_Month', 'sin_WeekOfYear',\n",
      "       'cos_WeekOfYear', 'is_holiday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import holidays\n",
    "us_holidays = holidays.US()\n",
    "\n",
    "def is_holiday(date):\n",
    "    date = date.replace(hour = 0)\n",
    "    return 1 if (date in us_holidays) else 0\n",
    "\n",
    "def add_holiday_col(df, holidays):\n",
    "    return df.assign(is_holiday = df['Date'].apply(is_holiday))\n",
    "\n",
    "df = add_holiday_col(df, us_holidays)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert symbol to number\n",
    "#TODO: This probably is not the best way to convert symbol to a numeric feature\n",
    "symbol_map = {}\n",
    "symbol_map_rev = {}\n",
    "\n",
    "symbols = df['Symbol'].unique()\n",
    "for i, symbol in enumerate(symbols):\n",
    "    symbol_map[symbol] = i\n",
    "    symbol_map_rev[i] = symbol\n",
    "\n",
    "df['Symbol_Num'] = df.apply(lambda row: symbol_map[row['Symbol']], axis=1)\n",
    "df = df.drop('Symbol', axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Split into Training and Test sets\n",
    "\n",
    "Do this by breaking data up into date ranges, as we are mirroing a live setup where we have the full \n",
    "past data, and need to predict the future. We are not trying to do things like, given random selctions\n",
    "of dates in the past predict a future date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_drop = ['Month', 'Date', 'DayOfWeek', 'WeekOfYear']\n",
    "\n",
    "# train_x = df[(df['Year']==2018) & (df['Month'] < 12)]\n",
    "# i1 = train_x.set_index(['Symbol_Num']).index\n",
    "# train_x = train_x.drop(cols_to_drop, axis=1)\n",
    "# train_y = df[(df['Year']==2018) & (df['Month'] == 12)]\n",
    "# i2 = train_y.set_index(['Symbol_Num']).index\n",
    "# train_y = train_y[i2.isin(i1)]\n",
    "# train_y = train_y.groupby('Symbol_Num').agg({'Volume':[\"mean\"]})\n",
    "\n",
    "# print(len(train_x), len(train_y))\n",
    "\n",
    "# val_x = df[(df['Year']==2019) & (df['Month'] < 6)]\n",
    "# i1 = val_x.set_index(['Symbol_Num']).index\n",
    "# val_x = val_x.drop(cols_to_drop, axis=1)\n",
    "# val_y = df[(df['Year']==2019) & (df['Month'] == 6)]\n",
    "# i2 = val_y.set_index(['Symbol_Num']).index\n",
    "# val_y = val_y[i2.isin(i1)]\n",
    "# val_y = val_y.groupby('Symbol_Num').agg({'Volume':[\"mean\"]})\n",
    "\n",
    "# print(len(val_x), len(val_y))\n",
    "\n",
    "\n",
    "# test_x = df[(df['Year']==2019) & (df['Month'] < 12) & (df['Month'] > 6)]\n",
    "# i1 = test_x.set_index(['Symbol_Num']).index\n",
    "# test_x = test_x.drop(cols_to_drop, axis=1).groupby('Symbol_Num')\n",
    "# test_y = df[(df['Year']==2019) & (df['Month'] == 12)]\n",
    "# i2 = test_y.set_index(['Symbol_Num']).index\n",
    "# test_y = test_y[i2.isin(i1)]\n",
    "# test_y = test_y.groupby('Symbol_Num').agg({'Volume':[\"mean\"]})\n",
    "\n",
    "# print(len(test_x), len(test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Month', 'Date', 'DayOfWeek', 'WeekOfYear']\n",
    "\n",
    "train_x = df[(df['Year']==2018) & (df['Month'] < 12)].drop(cols_to_drop, axis=1)\n",
    "train_y = df[(df['Year']==2018) & (df['Month'] == 12)].drop(cols_to_drop, axis=1)\n",
    "\n",
    "val_x = df[(df['Year']==2019) & (df['Month'] < 6)].drop(cols_to_drop, axis=1)\n",
    "val_y = df[(df['Year']==2019) & (df['Month'] == 6)].drop(cols_to_drop, axis=1)\n",
    "\n",
    "test_x = df[(df['Year']==2019) & (df['Month'] < 12) & (df['Month'] > 6)].drop(cols_to_drop, axis=1)\n",
    "test_y = df[(df['Year']==2019) & (df['Month'] == 12)].drop(cols_to_drop, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3332 3421 3523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#TODO: Would other types of scalers make a differnce\n",
    "xscaler = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "# t = scaler.fit_transform(train_x)\n",
    "# print(t.shape)\n",
    "#X_train_arr = transfrom_group(train_x, scaler)\n",
    "# X_val_arr = transfrom_group(val_x, scaler)\n",
    "# X_test_arr = transfrom_group(test_x, scaler)\n",
    "\n",
    "\n",
    "# y_train_arr = scaler.fit_transform(train_y)\n",
    "# y_val_arr = scaler.transform(val_y)\n",
    "# y_test_arr = scaler.transform(test_y)\n",
    "\n",
    "# print(len(X_train_arr), len(y_train_arr))\n",
    "# print(len(X_val_arr), len(y_val_arr))\n",
    "# print(len(X_test_arr), len(y_test_arr))\n",
    "\n",
    "def group(x,y):\n",
    "    out = {}\n",
    "    grouped = x.groupby('Symbol_Num')\n",
    "    yhat = y.groupby('Symbol_Num').agg({'Volume':[\"mean\"]})\n",
    "    yhat = dict(zip(yhat.index, yhat[('Volume', 'mean')]))\n",
    "    count = 0\n",
    "    for symbol, group in grouped:\n",
    "        if symbol in yhat:\n",
    "            out[count] = {'x':group, 'y':yhat[symbol]}\n",
    "            count+=1\n",
    "    return out\n",
    "\n",
    "train_grouped = group(train_x, train_y)\n",
    "val_grouped = group(val_x, val_y)\n",
    "test_grouped = group(test_x, test_y)\n",
    "\n",
    "xscaler.fit(train_x)\n",
    "t = list(train_grouped.values())\n",
    "y_vals = list(map(lambda x: x['y'], train_grouped.values()))\n",
    "y_vals = np.array(y_vals)\n",
    "y_vals = y_vals.reshape(-1, 1)\n",
    "yscaler.fit(y_vals)\n",
    "\n",
    "def scale_group(group, xscaler, yscaler):\n",
    "    out = {}\n",
    "    for key, item in group.items():\n",
    "        x = xscaler.transform(item['x'])\n",
    "        y = yscaler.transform(np.atleast_1d(item['y']).reshape(-1, 1))\n",
    "        out[key] = {'x':x,'y':y[0][0]}\n",
    "    return out\n",
    "\n",
    "train_grouped_scaled = scale_group(train_grouped,xscaler,yscaler)\n",
    "val_grouped_scaled = scale_group(val_grouped,xscaler,yscaler)\n",
    "test_grouped_scaled = scale_group(test_grouped,xscaler,yscaler)\n",
    "\n",
    "print(len(train_grouped_scaled), len(val_grouped_scaled), len(test_grouped_scaled))\n",
    "\n",
    "#train_x_scaled = pd.DataFrame(scaler.fit_transform(train_x),columns = train_x.columns)\n",
    "#train_y_scaled = pd.DataFrame(scaler.transform(train_y),columns = train_y.columns)\n",
    "\n",
    "#val_x_scaled = pd.DataFrame(scaler.fit_transform(val_x),columns = val_x.columns)\n",
    "#val_y_scaled = pd.DataFrame(scaler.transform(val_y),columns = val_y.columns)\n",
    "\n",
    "#test_x_scaled = pd.DataFrame(scaler.fit_transform(test_x),columns = test_x.columns)\n",
    "#test_y_scaled = pd.DataFrame(scaler.transform(test_y),columns = test_y.columns)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from numpy import argsort\n",
    "\n",
    "# Create a custom dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        y = y_data.groupby('Symbol_Num').agg({'Volume':[\"mean\"]})\n",
    "        self.y_data = dict(zip(y.index, y[('Volume', 'mean')]))\n",
    "\n",
    "        symbols = x_data.groupby('Symbol_Num').groups.keys()\n",
    "        y_symbols = y_data.groupby('Symbol_Num').groups\n",
    "        self.symbol_nums = {}\n",
    "        count = 0\n",
    "        for key in symbols:\n",
    "            if key in y_symbols:\n",
    "                self.symbol_nums[count] = key\n",
    "                count += 1\n",
    "        # y = set(y_symbols.keys())\n",
    "        # x = set(self.symbol_nums.values())\n",
    "        # print(len(x.intersection(y)))\n",
    "        # print(-1.7371406599594579 in y)\n",
    "        self.len = count\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        symbol = self.symbol_nums[idx]\n",
    "        y = self.y_data[symbol]\n",
    "        x_data = self.x_data[self.x_data[\"Symbol_Num\"]==symbol]\n",
    "        t = torch.tensor(x_data.values, dtype=torch.float32) #cast to float32 for faster computation\n",
    "        return t, y, len(x_data)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_x_scaled, train_y_scaled)\n",
    "val_dataset = TimeSeriesDataset(val_x_scaled, val_y_scaled)\n",
    "test_dataset = TimeSeriesDataset(test_x_scaled, test_y_scaled)\n",
    "\n",
    "def time_series_collate(batch):\n",
    "    #print(len(batch[0]))\n",
    "    sequence = []\n",
    "    y_vals = []\n",
    "    lengths = []\n",
    "    #pack padded zeros requires inputs to be sorted by length\n",
    "    sorted_indexes = list(reversed(argsort(list(map(lambda x: x[2], batch)))))\n",
    "    for i in sorted_indexes:\n",
    "        sequence.append(batch[i][0])\n",
    "        y_vals.append(batch[i][1])\n",
    "        lengths.append(batch[i][2])\n",
    "    # Pad sequences with zeros to make them the same length\n",
    "    return pad_sequence(sequence, batch_first=True, padding_value=0), torch.Tensor(y_vals), torch.Tensor(lengths)\n",
    "\n",
    "#TODO: Is there a better approach here than just dropping the last batch\n",
    "#TODO: Weights and Balances - optimize batch size\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=time_series_collate, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=time_series_collate, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=time_series_collate, drop_last=True)\n",
    "test_loader_one = DataLoader(test_dataset, batch_size=1, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0216, -0.0220, -0.0208,  ...,  1.6189, -0.0944, -1.7038],\n",
      "         [-0.0216, -0.0220, -0.0208,  ...,  1.6189, -0.0944, -1.7038],\n",
      "         [-0.0216, -0.0220, -0.0208,  ...,  1.6189, -0.0944, -1.7038],\n",
      "         ...,\n",
      "         [-0.0216, -0.0220, -0.0208,  ...,  1.4588, -0.0944, -1.7038],\n",
      "         [-0.0216, -0.0220, -0.0208,  ...,  1.4588, -0.0944, -1.7038],\n",
      "         [-0.0216, -0.0219, -0.0207,  ...,  1.4588, -0.0944, -1.7038]],\n",
      "\n",
      "        [[-0.0152, -0.0152, -0.0148,  ...,  1.6189, -0.0944, -1.7218],\n",
      "         [-0.0151, -0.0154, -0.0148,  ...,  1.6189, -0.0944, -1.7218],\n",
      "         [-0.0151, -0.0153, -0.0149,  ...,  1.6189, -0.0944, -1.7218],\n",
      "         ...,\n",
      "         [-0.0166, -0.0168, -0.0162,  ...,  1.4588, -0.0944, -1.7218],\n",
      "         [-0.0166, -0.0167, -0.0160,  ...,  1.4588, -0.0944, -1.7218],\n",
      "         [-0.0165, -0.0167, -0.0161,  ...,  1.4588, -0.0944, -1.7218]],\n",
      "\n",
      "        [[-0.0184, -0.0186, -0.0176,  ...,  1.6189, -0.0944, -1.7086],\n",
      "         [-0.0183, -0.0187, -0.0178,  ...,  1.6189, -0.0944, -1.7086],\n",
      "         [-0.0184, -0.0188, -0.0178,  ...,  1.6189, -0.0944, -1.7086],\n",
      "         ...,\n",
      "         [-0.0181, -0.0183, -0.0174,  ...,  1.4588, -0.0944, -1.7086],\n",
      "         [-0.0181, -0.0184, -0.0174,  ...,  1.4588, -0.0944, -1.7086],\n",
      "         [-0.0182, -0.0183, -0.0176,  ...,  1.4588, -0.0944, -1.7086]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0215, -0.0219, -0.0206,  ..., -0.3926, -0.0944, -1.6968],\n",
      "         [-0.0215, -0.0217, -0.0206,  ..., -0.3926, -0.0944, -1.6968],\n",
      "         [-0.0214, -0.0217, -0.0205,  ..., -0.5570, -0.0944, -1.6968],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0208, -0.0215, -0.0199,  ..., -1.3128, -0.0944, -1.6961],\n",
      "         [-0.0211, -0.0214, -0.0202,  ..., -1.3453, -0.0944, -1.6961],\n",
      "         [-0.0210, -0.0212, -0.0200,  ..., -1.3453, -0.0944, -1.6961],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0212, -0.0216, -0.0204,  ..., -1.3453, -0.0944, -1.6746],\n",
      "         [-0.0212, -0.0216, -0.0204,  ..., -1.3453, -0.0944, -1.6746],\n",
      "         [-0.0212, -0.0216, -0.0204,  ..., -1.3453, -0.0944, -1.6746],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), tensor([-0.1081, -0.1700, -0.2144, -0.2137,  4.8449, -0.0146, -0.1707, -0.2120,\n",
      "        -0.1705, -0.2074, -0.1300, -0.1628,  0.1617, -0.2147, -0.1699, -0.2138,\n",
      "        -0.0445, -0.1395, -0.2145, -0.0283, -0.0836, -0.2122, -0.2101, -0.1087,\n",
      "        -0.2138, -0.2152, -0.2118, -0.0223, -0.2153, -0.1496, -0.1979, -0.1289,\n",
      "        -0.2116,  0.0541,  0.0197, -0.2086,  1.1946,  0.3944, -0.2153, -0.1782,\n",
      "        -0.2135,  0.0070,  1.4180, -0.1978, -0.1899,  0.1733,  1.3467, -0.1073,\n",
      "        -0.0949, -0.0494,  0.0810, -0.1638, -0.0998, -0.2060, -0.2132, -0.2147,\n",
      "         0.0694, -0.1321, -0.2138, -0.1958, -0.2108,  0.0692, -0.2073, -0.2131]), tensor([232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232.,\n",
      "        232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232.,\n",
      "        232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232.,\n",
      "        232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232.,\n",
      "        232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 232., 216.,\n",
      "        211., 158., 118., 117.]))\n"
     ]
    }
   ],
   "source": [
    "#print(len(train_dataset))\n",
    "#train_dataset[0]\n",
    "\n",
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.layer_dim = layer_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        #unpad \n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        \n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "\n",
    "        #pad back to expected length\n",
    "        out, lengths = pad_packed_sequence(out, batch_first=True)\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y, lengths):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x, lengths)\n",
    "\n",
    "        #print(y.shape, yhat.shape)\n",
    "        #print(y)\n",
    "        #print(y, yhat)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
    "        model_path = f'models/gru_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            count = 0\n",
    "            for x_batch, y_batch, lengths in train_loader:\n",
    "                #TODO: What does this view do here?\n",
    "                #print(\"DIMS: \", x_batch.shape)\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
    "                y_batch = y_batch.view([batch_size,-1]).to(device)\n",
    "                loss = self.train_step(x_batch, y_batch, lengths)\n",
    "                batch_losses.append(loss)\n",
    "                count += 1\n",
    "                if not count % 15:\n",
    "                    print(\"Epoch {}, Batch Num: {}, Loss: {}\".format(epoch, count, loss))\n",
    "\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val, lengths in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
    "                    y_val = y_val.view([batch_size,-1]).view([batch_size,-1]).to(device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val, lengths)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            print(\n",
    "                f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            for x_test, y_test, lengths in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "                y_test = y_test.view([batch_size,-1]).to(device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test, lengths)\n",
    "                predictions.append(yhat.to(device).detach().numpy())\n",
    "                values.append(y_test.to(device).detach().numpy())\n",
    "\n",
    "        return predictions, values\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(model, model_params):\n",
    "    models = {\n",
    "        \"gru\": GRUModel,\n",
    "    }\n",
    "    return models.get(model.lower())(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "#TODO: get this working on GPU\n",
    "# Set the device\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch Num: 15, Loss: 0.030896976590156555\n",
      "Epoch 1, Batch Num: 30, Loss: 0.03908456489443779\n",
      "Epoch 1, Batch Num: 45, Loss: 0.024201523512601852\n",
      "[1/15] Training loss: 0.7627\t Validation loss: 1.3091\n",
      "Epoch 2, Batch Num: 15, Loss: 0.11441574990749359\n",
      "Epoch 2, Batch Num: 30, Loss: 0.035680968314409256\n",
      "Epoch 2, Batch Num: 45, Loss: 0.0389910563826561\n",
      "[2/15] Training loss: 0.5581\t Validation loss: 0.5713\n",
      "Epoch 3, Batch Num: 15, Loss: 0.1641879677772522\n",
      "Epoch 3, Batch Num: 30, Loss: 0.047281425446271896\n",
      "Epoch 3, Batch Num: 45, Loss: 0.04727094620466232\n",
      "[3/15] Training loss: 0.4410\t Validation loss: 0.7522\n",
      "Epoch 4, Batch Num: 15, Loss: 0.12468023598194122\n",
      "Epoch 4, Batch Num: 30, Loss: 0.029003383591771126\n",
      "Epoch 4, Batch Num: 45, Loss: 0.028319213539361954\n",
      "[4/15] Training loss: 0.3655\t Validation loss: 0.5774\n",
      "Epoch 5, Batch Num: 15, Loss: 0.07668980211019516\n",
      "Epoch 5, Batch Num: 30, Loss: 0.07125762850046158\n",
      "Epoch 5, Batch Num: 45, Loss: 0.024183008819818497\n",
      "[5/15] Training loss: 0.3341\t Validation loss: 0.6476\n",
      "Epoch 6, Batch Num: 15, Loss: 0.07863155007362366\n",
      "Epoch 6, Batch Num: 30, Loss: 0.021138114854693413\n",
      "Epoch 6, Batch Num: 45, Loss: 0.019845733419060707\n",
      "[6/15] Training loss: 0.2312\t Validation loss: 1.0285\n",
      "Epoch 7, Batch Num: 15, Loss: 0.1678944230079651\n",
      "Epoch 7, Batch Num: 30, Loss: 0.04065417870879173\n",
      "Epoch 7, Batch Num: 45, Loss: 0.048532627522945404\n",
      "[7/15] Training loss: 0.2509\t Validation loss: 0.6971\n",
      "Epoch 8, Batch Num: 15, Loss: 0.0786287859082222\n",
      "Epoch 8, Batch Num: 30, Loss: 0.016231874004006386\n",
      "Epoch 8, Batch Num: 45, Loss: 0.03903559595346451\n",
      "[8/15] Training loss: 0.1770\t Validation loss: 1.0382\n",
      "Epoch 9, Batch Num: 15, Loss: 0.09653932601213455\n",
      "Epoch 9, Batch Num: 30, Loss: 0.08969560265541077\n",
      "Epoch 9, Batch Num: 45, Loss: 0.041833847761154175\n",
      "[9/15] Training loss: 0.2252\t Validation loss: 1.2046\n",
      "Epoch 10, Batch Num: 15, Loss: 0.09405837208032608\n",
      "Epoch 10, Batch Num: 30, Loss: 0.021160122007131577\n",
      "Epoch 10, Batch Num: 45, Loss: 0.0305241160094738\n",
      "[10/15] Training loss: 0.1471\t Validation loss: 1.1573\n",
      "Epoch 11, Batch Num: 15, Loss: 0.04620331525802612\n",
      "Epoch 11, Batch Num: 30, Loss: 0.05060379207134247\n",
      "Epoch 11, Batch Num: 45, Loss: 0.02350505068898201\n",
      "[11/15] Training loss: 0.1744\t Validation loss: 2.6302\n",
      "Epoch 12, Batch Num: 15, Loss: 0.017639074474573135\n",
      "Epoch 12, Batch Num: 30, Loss: 0.01933438330888748\n",
      "Epoch 12, Batch Num: 45, Loss: 0.024996772408485413\n",
      "[12/15] Training loss: 0.1311\t Validation loss: 2.7205\n",
      "Epoch 13, Batch Num: 15, Loss: 0.03194542974233627\n",
      "Epoch 13, Batch Num: 30, Loss: 0.025228871032595634\n",
      "Epoch 13, Batch Num: 45, Loss: 0.02719484269618988\n",
      "[13/15] Training loss: 0.1210\t Validation loss: 2.3836\n",
      "Epoch 14, Batch Num: 15, Loss: 0.02136315405368805\n",
      "Epoch 14, Batch Num: 30, Loss: 0.02348267287015915\n",
      "Epoch 14, Batch Num: 45, Loss: 0.030575234442949295\n",
      "[14/15] Training loss: 0.1273\t Validation loss: 2.3370\n",
      "Epoch 15, Batch Num: 15, Loss: 0.01434345543384552\n",
      "Epoch 15, Batch Num: 30, Loss: 0.013231023214757442\n",
      "Epoch 15, Batch Num: 45, Loss: 0.04783676564693451\n",
      "[15/15] Training loss: 0.1047\t Validation loss: 1.9706\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#TODO: Optimize these paramaters - Weights and Balances\n",
    "input_dim = len(train_x.columns)\n",
    "output_dim = 1\n",
    "hidden_dim = 64\n",
    "layer_dim = 3\n",
    "batch_size = 64\n",
    "dropout = 0.2\n",
    "n_epochs = 15\n",
    "learning_rate = 3e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n",
    "\n",
    "#TODO: Try other Models  - Weights and Balances\n",
    "model = get_model('gru', model_params).to(device)\n",
    "\n",
    "#TODO: Try other loss functions and optimizers - Weights and Balances\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#TODO: Optimize training performance\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "opt.plot_losses()\n",
    "\n",
    "predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)\n",
    "\n",
    "#TODO: Plot actual predictions vs averages to see how we did\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'Close', 'High', 'Low', 'Volume', 'AdjClose', 'Year',\n",
      "       'sin_DayOfWeek', 'cos_DayOfWeek', 'sin_Month', 'cos_Month',\n",
      "       'sin_WeekOfYear', 'cos_WeekOfYear', 'is_holiday', 'Symbol_Num'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3523,2) (15,) (3523,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m     df_result \u001b[39m=\u001b[39m inverse_transform(scaler, df_result, [[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m df_result\n\u001b[0;32m---> 17\u001b[0m df_result \u001b[39m=\u001b[39m format_predictions(predictions, values, test_x, scaler)\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mformat_predictions\u001b[0;34m(predictions, values, df_test, scaler)\u001b[0m\n\u001b[1;32m     11\u001b[0m df_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: vals, \u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m: preds}, index\u001b[39m=\u001b[39mdf_test\u001b[39m.\u001b[39mhead(\u001b[39mlen\u001b[39m(vals))\u001b[39m.\u001b[39mindex)\n\u001b[1;32m     12\u001b[0m df_result \u001b[39m=\u001b[39m df_result\u001b[39m.\u001b[39msort_index()\n\u001b[0;32m---> 13\u001b[0m df_result \u001b[39m=\u001b[39m inverse_transform(scaler, df_result, [[\u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m]])\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m df_result\n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36minverse_transform\u001b[0;34m(scaler, df, columns)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(scaler, df, columns):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[0;32m----> 3\u001b[0m         df[col] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(df[col])\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/preprocessing/_data.py:1052\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_std:\n\u001b[0;32m-> 1052\u001b[0m         X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[1;32m   1053\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n\u001b[1;32m   1054\u001b[0m         X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3523,2) (15,) (3523,2) "
     ]
    }
   ],
   "source": [
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_predictions(predictions, values, df_test, scaler):\n",
    "    print(df_test.columns)\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result\n",
    "\n",
    "\n",
    "df_result = format_predictions(predictions, values, test_x, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
